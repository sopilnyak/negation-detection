{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.wrappers import FastText\n",
    "import pandas as pd\n",
    "import re\n",
    "import pymorphy2\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Путь к файлу с текстом\n",
    "corpora_path = './'\n",
    "\n",
    "# Путь к модели эмбеддингов\n",
    "# model_path = './models/news.model.bin'  # маленький корпус\n",
    "# model_path = '../models/ruwikiruscorpora.model.bin'  # большой корпус\n",
    "model_path = 'rutenten11_8.bin'  # большой корпус со стоп-словами\n",
    "\n",
    "EMBEDDING_SIZE = 100  # размер эмбеддинга\n",
    "MAX_SEQ_LENGTH = 30  # максимальное количество слов в предложении\n",
    "N_BATCH = 128  # размер батча\n",
    "\n",
    "# Путь к папке с предобученной моделью\n",
    "# rutent2_2: Presicion: 0.9664723032069971, Recall: 0.9477445997458704, F-score: 0.9570168404170009\n",
    "# rutent2_3: Presicion: 0.9608867775138559, Recall: 0.9637865311308768, F-score: 0.9623344699072238\n",
    "model_folder = 'rutent2_3'\n",
    "\n",
    "# Настройки сети\n",
    "LEARNING_RATE = .0001\n",
    "\n",
    "# Путь до словаря антонимов\n",
    "ANTONYMS_PATH = 'antonyms.txt'\n",
    "\n",
    "POSITIVE_ANSWER_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Текст\n",
    "SENTENCE = \"Наша забастовка не от хорошей жизни: не главное, что конкурс и аукцион выиграла Лагуна; главное, что многие будут закупаться вовсе не дешевыми бумагами.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Для первого и второго корпуса\n",
    "# embeddings_vectors = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "\n",
    "# Для третьего корпуса\n",
    "embeddings_vectors = FastText.load_fasttext_format(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Преобразуем объект EuclidianKeyedVectors в dict (для первого и второго корпуса)\n",
    "\n",
    "# embeddings_dict = {}\n",
    "# for key in embeddings_vectors.vocab:\n",
    "#     raw_word = key.split(\"_\")[0]\n",
    "#     embeddings_dict[raw_word] = embeddings_vectors[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Для третьего корпуса\n",
    "embeddings_dict = embeddings_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Размер эмбеддинга\n",
    "EMBEDDING_SIZE = len(embeddings_dict['не'])\n",
    "\n",
    "# Вектора, обозначающие является ли слово cue или нет\n",
    "CUE_VECTOR = np.ones(EMBEDDING_SIZE)\n",
    "NOT_CUE_VECTOR = np.zeros(EMBEDDING_SIZE)\n",
    "\n",
    "# Пустой вектор\n",
    "ZERO_VECTOR = np.zeros(EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Слова, которых нет в словаре эмбеддингов (только для теста)\n",
    "unsuccessful_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_word(word):\n",
    "    \n",
    "    word = word.lower()\n",
    "\n",
    "    # Если слово содержит цифры или другие посторонние символы, выкинем его\n",
    "    pattern = re.compile(\"[^а-яА-Яё]\")\n",
    "    if pattern.match(word) != None:\n",
    "        return False\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Для предложения data создает матрицу эмбеддингов и меток, где номер строки отвечает номеру слова.\n",
    "'''\n",
    "\n",
    "def generate_batch(data):\n",
    "\n",
    "    # Матрица эмбеддингов, номер строки -- это номер слова\n",
    "    embeddings = []\n",
    "\n",
    "    # Cue-матрица, номер строки -- это номер слова\n",
    "    cues = []\n",
    "    \n",
    "    # Текст предложения\n",
    "    text = \"\"\n",
    "    \n",
    "    # Сколько слов получилось по факту (после выкидывания неудавшихся эмбеддингов)\n",
    "    n_words = 0\n",
    "    \n",
    "    for word_orig in nltk.word_tokenize(data):\n",
    "        \n",
    "        word = prepare_word(word_orig)\n",
    "        if not word:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Записываем в матрицу эмбеддингов\n",
    "            embeddings.append(embeddings_dict[word])\n",
    "\n",
    "            if (word == 'не' or word == 'нет'):\n",
    "                cue_vector = CUE_VECTOR\n",
    "            else:\n",
    "                cue_vector = NOT_CUE_VECTOR\n",
    "\n",
    "            # Записываем в матрицу cue\n",
    "            cues.append(cue_vector)\n",
    "\n",
    "            text += word_orig + \" | \"\n",
    "            n_words += 1\n",
    "\n",
    "        except KeyError:\n",
    "            # В случае неудачи сохраняем в список неудавшихся слов\n",
    "            unsuccessful_embeddings.append(word)\n",
    "                \n",
    "    # Padding\n",
    "    for padding_index in range(MAX_SEQ_LENGTH - n_words):\n",
    "        embeddings.append(ZERO_VECTOR)\n",
    "        cues.append(ZERO_VECTOR)\n",
    "    \n",
    "    # Ограничиваем длину предложения величиной MAX_SEQ_LENGTH\n",
    "    embeddings = np.array(embeddings[:MAX_SEQ_LENGTH])\n",
    "    cues = np.array(cues[:MAX_SEQ_LENGTH])\n",
    "    \n",
    "    return np.concatenate((embeddings, cues), axis=1), text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Генерируем эмбеддинги для предложения (пока оно одно)\n",
    "sent_embeddings, sent_text = generate_batch(SENTENCE)\n",
    "embedding_batch = np.array([sent_embeddings])\n",
    "texts = np.array([sent_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30, 200)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(embedding_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Слова, для которых не удалось получить эмбеддинги\n",
    "set(unsuccessful_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_predict = embedding_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_predict shape: (1, 30, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_predict shape:\", X_predict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o_sopilniak/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/o_sopilniak/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adagrad, Adam\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузим модель\n",
    "\n",
    "json_file = open(os.path.join(model_folder, 'model.json'), 'r')\n",
    "\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "model.load_weights(os.path.join(model_folder, 'model.h5'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])  # 'adam', 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 30, 200)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_22 (Bidirectio (None, 30, 256)           336896    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 30, 2)             514       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 30, 2)             0         \n",
      "=================================================================\n",
      "Total params: 337,410\n",
      "Trainable params: 337,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_values_ = model.predict(X_predict)\n",
    "\n",
    "words = texts[0].split(\" | \")[:-1][:MAX_SEQ_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_final = []\n",
    "\n",
    "for value in predicted_values_[0]:\n",
    "    if value[0] > POSITIVE_ANSWER_THRESHOLD:\n",
    "        predicted_final.append([1., 0.])\n",
    "    else:\n",
    "        predicted_final.append([0., 1.])\n",
    "        \n",
    "predicted = np.array(predicted_final)[:, 0][:len(words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Наша | забастовка | не | от | хорошей | жизни | не | главное | что | конкурс | и | аукцион | выиграла | Лагуна | главное | что | многие | будут | закупаться | вовсе | не | дешевыми | бумагами | '"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Антонимы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузим словарь антонимов\n",
    "antonyms_dict = json.load(open(ANTONYMS_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "хороший: ['нехороший', 'дурной', 'плохой', 'дурной', 'нехороший', 'худой']\n",
      "главное: ['второстепенный']\n",
      "дешевыми: ['дорогой']\n"
     ]
    }
   ],
   "source": [
    "# Выведем пары слово - его синоним в контексте предложения\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    if predicted[i] == 1:\n",
    "\n",
    "        try:\n",
    "            antonyms = antonyms_dict[morph.parse(word)[0].normal_form.replace(\"ё\", \"е\")]\n",
    "            print(\"{}: {}\".format(word, antonyms))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Антоним не найден: \", word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
